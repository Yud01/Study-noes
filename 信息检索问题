问题 当我们想要检索一本书中是否包含某个单词 但是不包含另外一个单词 最简答的做法往往是直接从头到尾阅读这本书的全部内容 然后全部扫描确定 这种线性扫描方法被称为Grepping linux上一个代码grep也直接对应着这个功能 对于一个文字不大的书籍这个是可行的 但是往往现实情况这种扫描方法完全无法使用
一种非线性扫描的方法就出现 -> 也就是建立一个关联矩阵
对每个单词进行建立向量表 记录这个单词在哪些章节中出现 1 表示出现  0 表示没有出现  然后以布尔方式操作这些向量

但是这种方法仍然很耗费资源
例如我们拥有50万个词汇 然后存在于100万个文档中 这样我们就出现了 5000亿个元素 且由于每个文档只包含1000个单词 矩阵中超过99.8%都是0 -> 这也就是我们经常说的稀疏矩阵 在实际应用中用处很小 特别是机器学习中完全无法使用

两个用于衡量准确率的指标
1 准确率 Precision P
被检索到的文档是相关的 / 所有被检索到的文档 
2 召回率 Recall
被检索到的文档是相关的 / 所有相关的文档

现在回到刚才的例子 我们尝试进行优化 -> 引出一个核心概念 倒排索引 Inverted Index 其中命名的时候倒排这个单词完全没有意义 不知道为什么这样写 但是大佬这样叫我们就这样用了

基本的思想是 记录数据的两个部分
1 存在的所有单词 -> 使用词汇表/字典记录
2 Postings list 每个单词对应的文档编号 -> 也就是每个次对应的文档编号列表 （即这些词出现在哪些文档中）

|Term         |  Documents|
|Brutus      |Doc1, Doc2, Doc4|
|Caesar      |Doc1, Doc2, Doc4, D5|
|Calpurnia|Doc2|

这样 当我们搜索 Brutus AND Caesar AND NOT Calpurnia
- 取交集 → Doc1, Doc2, Doc4 ∩ Doc1, Doc2, Doc4, D5 = Doc1, Doc2, Doc4 
- 再排除 Calpurnia 出现的 Doc2 → 最终结果：Doc1, Doc4
看上去很简单 但如果直接用仍然是一个垃圾方法 （当然能够进行一定优化）

倒排索引的构建过程
倒排索引是现代搜索引擎的核心结构 
步骤1  收集文档 Doc1: Friends, Romans, countrymen. So let it be with Caesar ...
步骤2 分词 将每篇文档转换为一个词条Token
Tokens: Friends Romans countrymen So let it be with Caesar
步骤3 使用之前讲解的方法对语言进行预处理 包括小写化 词干提取 去标点化 使词标准化
friend roman countryman so let it be with caesar
步骤4 构建倒排索引 
从标准化的Tokens中建立倒排索引 


